import torch
import gradio as gr
from transformers import AutoTokenizer, AutoModelForCausalLM

MODEL_ID = "pqn-ai/pqn-ai-v1"

# Ø¨Ø±Ø§ÛŒ CPU Ù¾Ø§ÛŒØ¯Ø§Ø±
torch.set_num_threads(max(1, torch.get_num_threads() - 0))  # Ø§Ø®ØªÛŒØ§Ø±Ø§Ù‹ Ù…Ø­Ø¯ÙˆØ¯ Ú©Ù†

print("=== Loading Ù¾ÛŒ ÛŒØ§Ø± (Pey Yar) - PQN.AI ===")

tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, trust_remote_code=True)
model = AutoModelForCausalLM.from_pretrained(
    MODEL_ID,
    trust_remote_code=True,
    torch_dtype=torch.float32,      # Ø±ÙˆÛŒ CPU Ø§Ù…Ù†â€ŒØªØ±Ù‡
    device_map="cpu",
    low_cpu_mem_usage=True
).eval()

SYSTEM_PROMPT_FA = (
    "ØªÙˆ Â«Ù¾ÛŒâ€ŒÛŒØ§Ø±Â» Ù‡Ø³ØªÛŒ: Ø¯Ø³ØªÛŒØ§Ø± Ú©ÙˆØ§Ù†ØªÙˆÙ…ÛŒ ÙØ§Ø±Ø³ÛŒâ€ŒØ¯Ø§Ù†ØŒ Ù…ÙˆØ¯Ø¨ØŒ Ø¯Ù‚ÛŒÙ‚ Ùˆ Ú©ÙˆØªØ§Ù‡â€ŒÙ†ÙˆÛŒØ³. "
    "Ø§Ú¯Ø± Ø³Ø¤Ø§Ù„ Ù…Ø¨Ù‡Ù… Ø¨ÙˆØ¯ØŒ ÛŒÚ© ØªÙˆØ¶ÛŒØ­ Ú©ÙˆØªØ§Ù‡ Ø¨Ù¾Ø±Ø³. Ø§Ø² Ø§Ø¯Ø¹Ø§Ù‡Ø§ÛŒ ØªØ§ÛŒÛŒØ¯Ù†Ø´Ø¯Ù‡ Ù¾Ø±Ù‡ÛŒØ² Ú©Ù†."
)
SYSTEM_PROMPT_EN = (
    "You are 'PiYar': a concise, helpful, Persian-first quantum assistant. "
    "Ask a brief clarifying question if the user prompt is ambiguous. Avoid unverifiable claims."
)

def build_chat_prompt(message, history):
    """ØªØ¨Ø¯ÛŒÙ„ ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ø¨Ù‡ Ù¾Ø±Ø§Ù…Ù¾Øª Ø®Ø·ÛŒ Ù¾Ø§ÛŒØ¯Ø§Ø± Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¨Ø¯ÙˆÙ† chat_template"""
    lines = [f"[SYSTEM_FA] {SYSTEM_PROMPT_FA}", f"[SYSTEM_EN] {SYSTEM_PROMPT_EN}"]
    for user, assistant in history or []:
        if user:
            lines.append(f"[USER] {user}".strip())
        if assistant:
            lines.append(f"[ASSISTANT] {assistant}".strip())
    lines.append(f"[USER] {message}".strip())
    lines.append("[ASSISTANT]")
    return "\n".join(lines)

def generate(message, history, temperature, top_p, top_k, max_new_tokens, repetition_penalty):
    try:
        # Ø³Ø§Ø®Øª Ù¾Ø±Ø§Ù…Ù¾Øª
        prompt = build_chat_prompt(message, history)

        # ØªÙˆÚ©Ù†Ø§ÛŒØ² Ø¨Ø§ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø·ÙˆÙ„ Ø§Ù…Ù†
        inputs = tokenizer(prompt, return_tensors="pt", truncation=True, max_length=2048)
        input_ids = inputs["input_ids"].to(model.device)

        with torch.no_grad():
            output_ids = model.generate(
                input_ids=input_ids,
                do_sample=True,
                temperature=float(temperature),
                top_p=float(top_p),
                top_k=int(top_k),
                repetition_penalty=float(repetition_penalty),
                max_new_tokens=int(max_new_tokens),
                pad_token_id=tokenizer.eos_token_id,
                eos_token_id=tokenizer.eos_token_id
            )

        # Ø¨Ø®Ø´ Ø¬Ø¯ÛŒØ¯ Ø±Ø§ Ø¬Ø¯Ø§ Ú©Ù†
        gen_ids = output_ids[0][input_ids.shape[1]:]
        text = tokenizer.decode(gen_ids, skip_special_tokens=True)

        # ØªÙ…ÛŒØ²Ú©Ø§Ø±ÛŒ Ø®Ø±ÙˆØ¬ÛŒ
        text = text.strip()
        if not text:
            text = "Ø®Ø±ÙˆØ¬ÛŒ Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø¨ÙˆØ¯Ø› Ù„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù† ÛŒØ§ Ø¬Ù…Ù„Ù‡ Ø±Ø§ Ú©Ù…ÛŒ Ø¨Ø§Ø²Ù†ÙˆÛŒØ³ÛŒ Ú©Ù†."

        return text

    except Exception as e:
        print(f"Error in generation: {e}")
        return f"Ø®Ø·Ø§ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø®: {str(e)}"

# Create premium chat interface with Pey Yar logo
demo = gr.ChatInterface(
    fn=generate,
    title="ğŸŸ£ Ù¾ÛŒ ÛŒØ§Ø± (Pey Yar) - PQN.AI",
    description="ØªØ¬Ø±Ø¨Ù‡ Ù†Ø³Ø®Ù‡ Ù†Ù…Ø§ÛŒØ´ÛŒ: Ù¾Ø§Ø³Ø® Ú©ÙˆØªØ§Ù‡ØŒ Ø¯Ù‚ÛŒÙ‚ Ùˆ ÙØ§Ø±Ø³ÛŒâ€ŒØ§ÙˆÙ„. (CPU Demo)",
    chatbot=gr.Chatbot(
        avatar_images=["https://huggingface.co/spaces/pqn-ai/pqn-ai-demo/resolve/main/pey_yar_logo.png", None],
        height=400
    ),
    additional_inputs=[
        gr.Slider(0.1, 1.5, value=0.7, step=0.05, label="Temperature"),
        gr.Slider(0.3, 1.0, value=0.9, step=0.05, label="Top-p"),
        gr.Slider(0, 100, value=40, step=5, label="Top-k"),
        gr.Slider(16, 1024, value=256, step=16, label="Max new tokens"),
        gr.Slider(1.0, 1.5, value=1.08, step=0.01, label="Repetition penalty"),
    ],
    examples=[
        "Ø³Ù„Ø§Ù…! ÛŒÚ© Ø¯Ø§Ø³ØªØ§Ù† Ø®ÛŒÙ„ÛŒ Ú©ÙˆØªØ§Ù‡ Ø¹Ù„Ù…ÛŒâ€Œ-ØªØ®ÛŒÙ„ÛŒ Ø¨Ù†ÙˆÛŒØ³.",
        "ÛŒÚ© Ø´Ø¹Ø± Ø³Ù‡â€ŒØ³Ø·Ø±ÛŒ Ø¯Ø±Ø¨Ø§Ø±Ù‡ Â«Ø§Ù…ÛŒØ¯ Ú©ÙˆØ§Ù†ØªÙˆÙ…ÛŒÂ» Ø¨Ú¯Ùˆ.",
        "Ø¯Ø± ÛŒÚ© Ù¾Ø§Ø±Ø§Ú¯Ø±Ø§ÙØŒ Ù¾ÛŒ ÛŒØ§Ø± Ø±Ø§ Ù…Ø¹Ø±ÙÛŒ Ú©Ù†.",
    ],
)

if __name__ == "__main__":
    demo.launch()
